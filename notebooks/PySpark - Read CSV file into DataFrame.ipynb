{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1e864a-7ca6-4d50-ba90-f5918cee79f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR_ID</th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A. Kannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Aaron M. Tenenbaum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Adam Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Adity Gupta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alex lonescu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUTHOR_ID         AUTHOR_NAME\n",
       "0          1           A. Kannan\n",
       "1          2  Aaron M. Tenenbaum\n",
       "2          3          Adam Smith\n",
       "3          4         Adity Gupta\n",
       "4          5        Alex lonescu"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Read file into DataFrame').getOrCreate()\n",
    "\n",
    "author = spark.read.csv('content/authors.csv', sep = ',', inferSchema = True, header = True)\n",
    "\n",
    "df = author.toPandas()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8da42b5d-402c-4488-8f5a-c3b5f4f01d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/03 13:51:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: BOOK_ID, AUTHOR_ID\n",
      " Schema: AUTHOR_ID, AUTHOR_NAME\n",
      "Expected: AUTHOR_ID but found: BOOK_ID\n",
      "CSV file: file:///Users/nptan2005/SourceCode/PythonDev/AI_Learning/pySpark/content/book_author.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR_ID</th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A. Kannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Aaron M. Tenenbaum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Adam Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Adity Gupta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alex lonescu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AUTHOR_ID         AUTHOR_NAME\n",
       "0         1           A. Kannan\n",
       "1         2  Aaron M. Tenenbaum\n",
       "2         3          Adam Smith\n",
       "3         4         Adity Gupta\n",
       "4         5        Alex lonescu"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR_ID</th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>B0209</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>B0210</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>B0211</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>B0212</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>B0213</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUTHOR_ID AUTHOR_NAME\n",
       "724     B0209         153\n",
       "725     B0210         292\n",
       "726     B0211         317\n",
       "727     B0212         278\n",
       "728     B0213         287"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR_ID</th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A. Kannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Aaron M. Tenenbaum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Adam Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Adity Gupta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alex lonescu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>B0209</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>B0210</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>B0211</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>B0212</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>B0213</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUTHOR_ID         AUTHOR_NAME\n",
       "0           1           A. Kannan\n",
       "1           2  Aaron M. Tenenbaum\n",
       "2           3          Adam Smith\n",
       "3           4         Adity Gupta\n",
       "4           5        Alex lonescu\n",
       "724     B0209                 153\n",
       "725     B0210                 292\n",
       "726     B0211                 317\n",
       "727     B0212                 278\n",
       "728     B0213                 287"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.appName('Read Multi CSV files').getOrCreate()\n",
    "\n",
    "path = ['content/authors.csv','content/book_author.csv']\n",
    "\n",
    "files = spark.read.csv(path, sep = ',', inferSchema = True, header = True)\n",
    "\n",
    "df1 = files.toPandas()\n",
    "\n",
    "display(df1.head())\n",
    "display(df1.tail())\n",
    "\n",
    "combined = pd.concat([df1.head(), df1.tail()])\n",
    "\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fa6fdf0-2b3d-40f7-8176-f9fdaf6f35d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/03 14:07:14 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: content/*.csv.\n",
      "java.io.FileNotFoundException: File content/*.csv does not exist\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:917)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1238)\n",
      "\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:907)\n",
      "\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:56)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:381)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.org$apache$spark$sql$catalyst$analysis$ResolveDataSource$$loadV1BatchSource(ResolveDataSource.scala:143)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.$anonfun$applyOrElse$2(ResolveDataSource.scala:61)\n",
      "\tat scala.Option.getOrElse(Option.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:61)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource$$anonfun$apply$1.applyOrElse(ResolveDataSource.scala:45)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:139)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:139)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:416)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:131)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:112)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:111)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:37)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:45)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.ResolveDataSource.apply(ResolveDataSource.scala:43)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)\n",
      "\tat scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)\n",
      "\tat scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:79)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:334)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:340)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:336)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:234)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:336)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:299)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:330)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)\n",
      "\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)\n",
      "\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)\n",
      "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:109)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.load(DataFrameReader.scala:58)\n",
      "\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:392)\n",
      "\tat org.apache.spark.sql.classic.DataFrameReader.csv(DataFrameReader.scala:259)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/12/03 14:07:15 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 2, schema size: 9\n",
      "CSV file: file:///Users/nptan2005/SourceCode/PythonDev/AI_Learning/pySpark/content/book_author.csv\n",
      "25/12/03 14:07:15 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 2, schema size: 9\n",
      "CSV file: file:///Users/nptan2005/SourceCode/PythonDev/AI_Learning/pySpark/content/authors.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOOK_ID</th>\n",
       "      <th>BOOK_TITLE</th>\n",
       "      <th>BOOK_COST</th>\n",
       "      <th>BOOK_TYPE</th>\n",
       "      <th>PUBL_ID</th>\n",
       "      <th>BOOK_EDITION</th>\n",
       "      <th>BOOK_DISCOUNT</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>PUBL_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0056</td>\n",
       "      <td>DataBase Systems</td>\n",
       "      <td>935.27</td>\n",
       "      <td>DB</td>\n",
       "      <td>11</td>\n",
       "      <td>Fifth</td>\n",
       "      <td>10</td>\n",
       "      <td>978-8131716250</td>\n",
       "      <td>01-MAY-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0059</td>\n",
       "      <td>Database Systems</td>\n",
       "      <td>1003.67</td>\n",
       "      <td>DB</td>\n",
       "      <td>11</td>\n",
       "      <td>Eighth</td>\n",
       "      <td>10</td>\n",
       "      <td>978-8185015583</td>\n",
       "      <td>01-JAN-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0063</td>\n",
       "      <td>The Java TM Programming Language</td>\n",
       "      <td>425</td>\n",
       "      <td>PR</td>\n",
       "      <td>11</td>\n",
       "      <td>Third</td>\n",
       "      <td>10</td>\n",
       "      <td>978-8131702215</td>\n",
       "      <td>01-JAN-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0067</td>\n",
       "      <td>The Java TM EE5 Tutorial</td>\n",
       "      <td>725</td>\n",
       "      <td>PR</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>978-8131714928</td>\n",
       "      <td>03-NOV-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0071</td>\n",
       "      <td>The Complete Reference HTML &amp; XHTML</td>\n",
       "      <td>540</td>\n",
       "      <td>PR</td>\n",
       "      <td>15</td>\n",
       "      <td>Fourth</td>\n",
       "      <td>16</td>\n",
       "      <td>978-0070701946</td>\n",
       "      <td>08-MAR-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BOOK_ID                           BOOK_TITLE BOOK_COST BOOK_TYPE PUBL_ID  \\\n",
       "0   B0056                     DataBase Systems    935.27        DB      11   \n",
       "1   B0059                     Database Systems   1003.67        DB      11   \n",
       "2   B0063     The Java TM Programming Language       425        PR      11   \n",
       "3   B0067             The Java TM EE5 Tutorial       725        PR      11   \n",
       "4   B0071  The Complete Reference HTML & XHTML       540        PR      15   \n",
       "\n",
       "  BOOK_EDITION BOOK_DISCOUNT            ISBN  PUBL_DATE  \n",
       "0        Fifth            10  978-8131716250  01-MAY-08  \n",
       "1       Eighth            10  978-8185015583  01-JAN-02  \n",
       "2        Third            10  978-8131702215  01-JAN-08  \n",
       "3         None            18  978-8131714928  03-NOV-06  \n",
       "4       Fourth            16  978-0070701946  08-MAR-10  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Read all CSV').getOrCreate()\n",
    "\n",
    "files_2 = spark.read.csv('content/*.csv', inferSchema = True, header = True)\n",
    "\n",
    "df_2 = files_2.toPandas()\n",
    "\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894fd23a-b8b6-412d-adac-329888d2f3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720efa3c-7878-4698-96ee-b70fc2c9b27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
